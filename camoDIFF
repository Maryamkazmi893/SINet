{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12371970,"sourceType":"datasetVersion","datasetId":7800807},{"sourceId":12372564,"sourceType":"datasetVersion","datasetId":7801219},{"sourceId":458585,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":371747,"modelId":392640}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! git clone https://github.com/DengPingFan/SINet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T11:12:54.473056Z","iopub.execute_input":"2025-07-04T11:12:54.473693Z","iopub.status.idle":"2025-07-04T11:12:55.537057Z","shell.execute_reply.started":"2025-07-04T11:12:54.473666Z","shell.execute_reply":"2025-07-04T11:12:55.536155Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls /kaggle/input/codflage\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T12:03:48.279585Z","iopub.execute_input":"2025-07-04T12:03:48.280107Z","iopub.status.idle":"2025-07-04T12:03:48.406761Z","shell.execute_reply.started":"2025-07-04T12:03:48.280084Z","shell.execute_reply":"2025-07-04T12:03:48.406116Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/codflage/SINet-master')\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nimport os\nimport argparse\nimport imageio.v2 as imageio\nfrom Src.SINet import SINet_ResNet50\nfrom Src.utils.Dataloader import test_dataset\nfrom Src.utils.trainer import eval_mae, numpy2tensor\n\n\n\nclass Args:\n    testsize = 352\n    model_path = '/kaggle/input/camomodel/pytorch/default/1/SINet_40.pth'  # âœ… adjust if needed\n    test_save = '/kaggle/working/SINet-master/Result/2020-CVPR-SINet-New/'\n\nopt = Args()\n\n\nmodel = SINet_ResNet50().cuda()\nmodel.load_state_dict(torch.load(opt.model_path))\nmodel.eval()\n\nfor dataset in ['COD10K']:\n    save_path = opt.test_save + dataset + '/'\n    os.makedirs(save_path, exist_ok=True)\n    # NOTES:\n    #  if you plan to inference on your customized dataset without grouth-truth,\n    #  you just modify the params (i.e., `image_root=your_test_img_path` and `gt_root=your_test_img_path`)\n    #  with the same filepath. We recover the original size according to the shape of grouth-truth, and thus,\n    #  the grouth-truth map is unnecessary actually.\n    test_loader = test_dataset(\n    image_root='/kaggle/input/datasetcamou/TestDataset/{}/Imgs/'.format(dataset),\n    gt_root='/kaggle/input/datasetcamou/TestDataset/{}/GT/'.format(dataset),\n    testsize=opt.testsize)\n\n  \n    img_count = 1\n    for iteration in range(test_loader.size):\n        # load data\n        image, gt, name = test_loader.load_data()\n        gt = np.asarray(gt, np.float32)\n        gt /= (gt.max() + 1e-8)\n        image = image.cuda()\n        # inference\n        _, cam = model(image)\n        # reshape and squeeze\n        cam = F.upsample(cam, size=gt.shape, mode='bilinear', align_corners=True)\n        cam = cam.sigmoid().data.cpu().numpy().squeeze()\n        # normalize\n        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n        imageio.imwrite(save_path + name, (cam * 255).astype('uint8'))\n        # evaluate\n        mae = eval_mae(numpy2tensor(cam), numpy2tensor(gt))\n        # coarse score\n        print('[Eval-Test] Dataset: {}, Image: {} ({}/{}), MAE: {}'.format(dataset, name, img_count,\n                                                                           test_loader.size, mae))\n        img_count += 1\n\nprint(\"\\n[Congratulations! Testing Done]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T13:24:13.221082Z","iopub.execute_input":"2025-07-04T13:24:13.221707Z","iopub.status.idle":"2025-07-04T13:26:58.029780Z","shell.execute_reply.started":"2025-07-04T13:24:13.221682Z","shell.execute_reply":"2025-07-04T13:26:58.029008Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#writefile /kaggle/working/mycam/SINet/MyTest.py\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nimport os\nimport argparse\nimport sys\nsys.path.append('/kaggle/input/sinetcamouflage/SINet-master')\n\nimport imageio.v2 as imageio\nfrom Src.SINet import SINet_ResNet50\nfrom Src.utils.Dataloader import test_dataset\nfrom Src.utils.trainer import eval_mae, numpy2tensor\n\n\n\nmodel = SINet_ResNet50().cuda()\nmodel.load_state_dict(torch.load(opt.model_path))\nmodel.eval()\n\nfor dataset in ['COD10K']:\n    save_path = opt.test_save + dataset + '/'\n    os.makedirs(save_path, exist_ok=True)\n    # NOTES:\n    #  if you plan to inference on your customized dataset without grouth-truth,\n    #  you just modify the params (i.e., `image_root=your_test_img_path` and `gt_root=your_test_img_path`)\n    #  with the same filepath. We recover the original size according to the shape of grouth-truth, and thus,\n    #  the grouth-truth map is unnecessary actually.\n    test_loader = test_dataset(image_root='./kaggle/input/cod10k-dataset/COD10K-v3/Test/Image',\n                               gt_root='/kaggle/input/cod10k-dataset/COD10K-v3/Test/GT_Object',\n                               testsize=opt.testsize)\n    img_count = 1\n    for iteration in range(test_loader.size):\n        # load data\n        image, gt, name = test_loader.load_data()\n        gt = np.asarray(gt, np.float32)\n        gt /= (gt.max() + 1e-8)\n        image = image.cuda()\n        # inference\n        _, cam = model(image)\n        # reshape and squeeze\n        cam = F.upsample(cam, size=gt.shape, mode='bilinear', align_corners=True)\n        cam = cam.sigmoid().data.cpu().numpy().squeeze()\n        # normalize\n        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n        imageio.imwrite(save_path + name, (cam * 255).astype('uint8'))\n        \n        # evaluate\n        mae = eval_mae(numpy2tensor(cam), numpy2tensor(gt))\n        # coarse score\n        print('[Eval-Test] Dataset: {}, Image: {} ({}/{}), MAE: {}'.format(dataset, name, img_count,\n                                                                           test_loader.size, mae))\n        img_count += 1\n\nprint(\"\\n[Congratulations! Testing Done]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T11:29:46.352335Z","iopub.execute_input":"2025-07-04T11:29:46.353221Z","iopub.status.idle":"2025-07-04T11:29:54.217604Z","shell.execute_reply.started":"2025-07-04T11:29:46.353179Z","shell.execute_reply":"2025-07-04T11:29:54.216631Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls /kaggle/working/mycam/SINet/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T07:38:31.227842Z","iopub.execute_input":"2025-07-04T07:38:31.228245Z","iopub.status.idle":"2025-07-04T07:38:31.360886Z","shell.execute_reply.started":"2025-07-04T07:38:31.228218Z","shell.execute_reply":"2025-07-04T07:38:31.360163Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cp -r /kaggle/input/sinetcamouflage/SINet-master /kaggle/working/\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T11:39:59.794520Z","iopub.execute_input":"2025-07-04T11:39:59.794866Z","iopub.status.idle":"2025-07-04T11:40:00.194508Z","shell.execute_reply.started":"2025-07-04T11:39:59.794842Z","shell.execute_reply":"2025-07-04T11:40:00.193648Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/working/SINet-master')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T11:40:42.989952Z","iopub.execute_input":"2025-07-04T11:40:42.990295Z","iopub.status.idle":"2025-07-04T11:40:42.994555Z","shell.execute_reply.started":"2025-07-04T11:40:42.990258Z","shell.execute_reply":"2025-07-04T11:40:42.993911Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"/kaggle/working/SINet-master/Src/utils/trainer.py\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T11:41:38.558316Z","iopub.execute_input":"2025-07-04T11:41:38.558621Z","iopub.status.idle":"2025-07-04T11:41:38.580918Z","shell.execute_reply.started":"2025-07-04T11:41:38.558598Z","shell.execute_reply":"2025-07-04T11:41:38.579975Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nano /kaggle/input/sinetcamouflage/SINet-master/Src/utils/trainer.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T11:44:38.141180Z","iopub.execute_input":"2025-07-04T11:44:38.141936Z","iopub.status.idle":"2025-07-04T11:44:38.154325Z","shell.execute_reply.started":"2025-07-04T11:44:38.141910Z","shell.execute_reply":"2025-07-04T11:44:38.153423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd //kaggle/working/mycam/SINet\n!python MyTest.py --model_path=/kaggle/input/camouflage/SINet_40.pth --test_save=/kaggle/working/test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:38:07.402311Z","iopub.execute_input":"2025-07-04T06:38:07.402605Z","iopub.status.idle":"2025-07-04T06:38:13.416489Z","shell.execute_reply.started":"2025-07-04T06:38:07.402579Z","shell.execute_reply":"2025-07-04T06:38:13.415788Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/mycam/SINet/Src/utils/Dataloader.py\nimport os\nfrom PIL import Image\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nimport cv2\nimport numpy as np\nimport torch\n\n\nclass CamObjDataset(data.Dataset):\n    def __init__(self, image_root, gt_root, trainsize):\n        self.trainsize = trainsize\n        self.images = sorted([\n    os.path.join(image_root, f) for f in os.listdir(image_root) if f.endswith('.jpg')\n])\n        self.gts = sorted([\n    os.path.join(gt_root, f) for f in os.listdir(gt_root) if f.endswith('.jpg') or f.endswith('.png')\n])\n        self.images = sorted(self.images)\n        self.gts = sorted(self.gts)\n        self.filter_files()\n        self.size = len(self.images)\n        self.img_transform = transforms.Compose([\n            transforms.Resize((self.trainsize, self.trainsize)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406],\n                                 [0.229, 0.224, 0.225])])\n        self.gt_transform = transforms.Compose([\n            transforms.Resize((self.trainsize, self.trainsize)),\n            transforms.ToTensor()])\n\n    def __getitem__(self, index):\n        image = self.rgb_loader(self.images[index])\n        gt = self.binary_loader(self.gts[index])\n        image = self.img_transform(image)\n        gt = self.gt_transform(gt)\n        return image, gt\n\n    def filter_files(self):\n        assert len(self.images) == len(self.gts)\n        images = []\n        gts = []\n        for img_path, gt_path in zip(self.images, self.gts):\n            img = Image.open(img_path)\n            gt = Image.open(gt_path)\n            if img.size == gt.size:\n                images.append(img_path)\n                gts.append(gt_path)\n        self.images = images\n        self.gts = gts\n\n    def rgb_loader(self, path):\n        with open(path, 'rb') as f:\n            img = Image.open(f)\n            return img.convert('RGB')\n\n    def binary_loader(self, path):\n        with open(path, 'rb') as f:\n            img = Image.open(f)\n            return img.convert('L')\n\n    def resize(self, img, gt):\n        assert img.size == gt.size\n        w, h = img.size\n        if h < self.trainsize or w < self.trainsize:\n            h = max(h, self.trainsize)\n            w = max(w, self.trainsize)\n            return img.resize((w, h), Image.BILINEAR), gt.resize((w, h), Image.NEAREST)\n        else:\n            return img, gt\n\n    def __len__(self):\n        return self.size\n\n\nclass test_dataset:\n    \"\"\"load test dataset (batchsize=1)\"\"\"\n    def __init__(self, image_root, gt_root, testsize):\n        self.testsize = testsize\n        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg')]\n        self.gts = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg') or f.endswith('.png')]\n        self.images = sorted(self.images)\n        self.gts = sorted(self.gts)\n        self.transform = transforms.Compose([\n            transforms.Resize((self.testsize, self.testsize)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n        self.gt_transform = transforms.ToTensor()\n        self.size = len(self.images)\n        self.index = 0\n\n    def load_data(self):\n        image = self.rgb_loader(self.images[self.index])\n        image = self.transform(image).unsqueeze(0)\n        gt = self.binary_loader(self.gts[self.index])\n        name = self.images[self.index].split('/')[-1]\n        if name.endswith('.jpg'):\n            name = name.split('.jpg')[0] + '.png'\n        self.index += 1\n        return image, gt, name\n\n    def rgb_loader(self, path):\n        with open(path, 'rb') as f:\n            img = Image.open(f)\n            return img.convert('RGB')\n\n    def binary_loader(self, path):\n        with open(path, 'rb') as f:\n            img = Image.open(f)\n            return img.convert('L')\n\n\nclass test_loader_faster(data.Dataset):\n    def __init__(self, image_root, testsize):\n        self.testsize = testsize\n        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg')]\n        self.images = sorted(self.images)\n        self.transform = transforms.Compose([\n            transforms.Resize((self.testsize, self.testsize)),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406],\n                                 [0.229, 0.224, 0.225])])\n        self.size = len(self.images)\n\n    def __getitem__(self, index):\n        images = self.rgb_loader(self.images[index])\n        images = self.transform(images)\n\n        img_name_list = self.images[index]\n\n        return images, img_name_list\n\n    def rgb_loader(self, path):\n        with open(path, 'rb') as f:\n            img = Image.open(f)\n            return img.convert('RGB')\n\n    def binary_loader(self, path):\n        with open(path, 'rb') as f:\n            img = Image.open(f)\n            return img.convert('L')\n\n    def __len__(self):\n        return self.size\n\n\ndef get_loader(image_root, gt_root, batchsize, trainsize, shuffle=True, num_workers=0, pin_memory=True):\n    # `num_workers=0` for more stable training\n    dataset = CamObjDataset(image_root, gt_root, trainsize)\n    data_loader = data.DataLoader(dataset=dataset,\n                                  batch_size=batchsize,\n                                  shuffle=shuffle,\n                                  num_workers=num_workers,\n                                  pin_memory=pin_memory)\n\n    return data_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:38:03.288307Z","iopub.execute_input":"2025-07-04T06:38:03.288604Z","iopub.status.idle":"2025-07-04T06:38:03.296478Z","shell.execute_reply.started":"2025-07-04T06:38:03.288577Z","shell.execute_reply":"2025-07-04T06:38:03.295811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install system deps\n!apt-get install -y ninja-build\n\n# Clone and install Apex\n!git clone https://github.com/NVIDIA/apex\n%cd apex\n!pip install -v --disable-pip-version-check --no-cache-dir ./\n%cd ..\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:24:00.543221Z","iopub.execute_input":"2025-07-04T06:24:00.543870Z","iopub.status.idle":"2025-07-04T06:24:15.628932Z","shell.execute_reply.started":"2025-07-04T06:24:00.543839Z","shell.execute_reply":"2025-07-04T06:24:15.628215Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile /kaggle/working/mycam/SINet/Src/utils/trainer.py\nimport torch\nfrom torch.autograd import Variable\nfrom datetime import datetime\nimport os\n#from apex import amp\nimport torch.nn.functional as F\n\n\ndef eval_mae(y_pred, y):\n    \"\"\"\n    evaluate MAE (for test or validation phase)\n    :param y_pred:\n    :param y:\n    :return: Mean Absolute Error\n    \"\"\"\n    return torch.abs(y_pred - y).mean()\n\n\ndef numpy2tensor(numpy):\n    \"\"\"\n    convert numpy_array in cpu to tensor in gpu\n    :param numpy:\n    :return: torch.from_numpy(numpy).cuda()\n    \"\"\"\n    return torch.from_numpy(numpy).cuda()\n\n\ndef clip_gradient(optimizer, grad_clip):\n    \"\"\"\n    recalibrate the misdirection in the training\n    :param optimizer:\n    :param grad_clip:\n    :return:\n    \"\"\"\n    for group in optimizer.param_groups:\n        for param in group['params']:\n            if param.grad is not None:\n                param.grad.data.clamp_(-grad_clip, grad_clip)\n\n\ndef adjust_lr(optimizer, epoch, decay_rate=0.1, decay_epoch=30):\n    decay = decay_rate ** (epoch // decay_epoch)\n    for param_group in optimizer.param_groups:\n        param_group['lr'] *= decay\n\n\ndef trainer(train_loader, model, optimizer, epoch, opt, loss_func, total_step):\n    \"\"\"\n    Training iteration\n    :param train_loader:\n    :param model:\n    :param optimizer:\n    :param epoch:\n    :param opt:\n    :param loss_func:\n    :param total_step:\n    :return:\n    \"\"\"\n    model.train()\n    for step, data_pack in enumerate(train_loader):\n        optimizer.zero_grad()\n        images, gts = data_pack\n        images = Variable(images).cuda()\n        gts = Variable(gts).cuda()\n\n        cam_sm, cam_im = model(images)\n        loss_sm = loss_func(cam_sm, gts)\n        loss_im = loss_func(cam_im, gts)\n        loss_total = loss_sm + loss_im\n\n        with amp.scale_loss(loss_total, optimizer) as scale_loss:\n            scale_loss.backward()\n\n        # clip_gradient(optimizer, opt.clip)\n        optimizer.step()\n\n        if step % 10 == 0 or step == total_step:\n            print('[{}] => [Epoch Num: {:03d}/{:03d}] => [Global Step: {:04d}/{:04d}] => [Loss_s: {:.4f} Loss_i: {:0.4f}]'.\n                  format(datetime.now(), epoch, opt.epoch, step, total_step, loss_sm.data, loss_im.data))\n\n    save_path = opt.save_model\n    os.makedirs(save_path, exist_ok=True)\n\n    if (epoch+1) % opt.save_epoch == 0:\n        torch.save(model.state_dict(), save_path + 'SINet_%d.pth' % (epoch+1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:28:04.902468Z","iopub.execute_input":"2025-07-04T06:28:04.903108Z","iopub.status.idle":"2025-07-04T06:28:04.908618Z","shell.execute_reply.started":"2025-07-04T06:28:04.903089Z","shell.execute_reply":"2025-07-04T06:28:04.907887Z"}},"outputs":[],"execution_count":null}]}